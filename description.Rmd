---
title: "Overview of Our Project and Some Exploratory Analysis"
author: "By Allison Newman, Elea Bach, Valentina Carducci, Natalie Gomas, and Natali Soraja"
date: "12/11/2021"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE)
```

## Overview and Motivation

As students, we all have commuted throughout Boston and Cambridge, via Uber/Lyft -- specifically Uber X and the non-luxury Lyft rides, which are the cheapest alternatives present on the apps. However, every time we open the app it feels like a guessing game: what will the wait time be? The cost of the ride? Are the prices of Uber going to be vastly different from Lyft? Should we take the T if it is running? How long should I wait to get a better price? These are only a few of the questions that a consistent user’s experience of ridesharing apps likely elicited. While each different scenario would require a specific cost-benefit analysis (how much money are you willing to spend, how much time do you have available, etc.), we believe it would be interesting to examine which aspects are involved with deciding whether to call an Uber/Lyft and how if there are any general trends in wait times and price for each app. In fact, we would like to understand the algorithms that these rideshare companies are using to set their prices and the distribution of Ubers/Lyft throughout the city at various times during the day.  

We believe that our results could be used by many users to minimize the frustration of the time one tries to wait in the hope of a decrease in prices. We would also like to understand if it is always more convenient to use one of the apps rather than the other choices to improve a user’s experience. 

## Related Work

The COVID-19 pandemic has influenced almost every aspect of our lives. Most of us were quarantined at some point and businesses were closed, leaving us very limited options for places to go. For the rideshare app drivers, the pandemic didn't allow for a safe environment to chauffer passengers. Consumers of ride share apps might notice changes in price patterns and availability since the pandemic. According to Boston Magazine at https://www.bostonmagazine.com/news/2021/07/01/uber-lyft-shortage-boston-passed/, one consumer remarks how  "a Lyft ride from the airport that once cost $23 was now going for more than $100". 
Taking inspiration from a previous BST260 final project by Lauren, Grabriel, and Joshua on predicting hubway station status, we were compelled to explore another alternative to taking the T. 

## Initial Questions

As a starting point, we considered the following scientific and inferential goals: <br> 

 - Predict price for Uber and Lyft rides based on time, day, weather, departure and destination area, and duration
 - Analyze which factors are the most influential to predict price <br> 
 - Compare different types of Ubers and Lyfts within their own company (i.e., prices of luxury cars compared to standard) <br> 
 - Understand the general geographical and monetary trends across the apps <br> 
 - Devise a user-friendly yet accurate predictive model for the price of Uber X and Lyft rides around Boston <br> 

As we were working on the analysis, we were able to answer all of our preliminary questions about the data and achieve our initial goals through the different kind of analyses that we conducted. 

On top of these questions,  we also realized that it would have been particularly interesting in this context to better understand how the surge multiplier that these app use is calculated -- since from our exploratory analysis and first models we saw that it was a very important variable to predict price.

## Data

This dataset is available to anyone from Kaggle's website at https://www.kaggle.com/brllrb/uber-and-lyft-dataset-boston-ma. The data covers rides completed by Uber and Lyft from November 26, 2018 to December 18, 2018. The author fails to mention that data's source, so we cannot verify investigate the validity of the data source and the data collection methods. However, as of December 8, 2021, the Kaggle page was viewed 22,200 times and the csv file was downloaded 3,070 times. The dataset is composed of 693,071 observations and 57 variables - these variables mainly include information on time, location, price, car type, and weather. 


## Exploratory Analysis

```{r message=FALSE, warning=FALSE}
library(ggplot2)
library(tidyverse)
library(lubridate)
library(grid)
require(gridExtra)
```

First, we'll read in our data.

```{r}
#read the data and store it into a data frame
data = read.csv(unz("rideshare_kaggle.csv.zip", "rideshare_kaggle.csv"))
```


```{r}
dim(data)
```

#### All available columns : 
```{r}
colnames(data)
```

Our initial data set has **693,071 observations**, with **57 features** each such as day, destination, name, distance and much more. There are 307,408 observations corresponding to Lyft and 385,663 corresponding to Uber, which gives a pretty balanced data set.

Conversion of datetime and creation of two new variables : 

* time : with date and time
* date : with only date

```{r}
data$time = as.POSIXct(data$datetime, format="%Y-%m-%d %H:%M:%S")
```

```{r}
data$date = as.POSIXct(data$datetime, format="%Y-%m-%d")
```

#### Exploration of types of rides 

```{r}
table(data$cab_type)
```

```{r}
table(data$name)
```

The names are not very clear, which ones belong to Lyft? Uber? What's "Taxi"? We'll decide which car types correspond to which company in the hypothesis testing section.

#### Exploration of the "price" variable : 

```{r}
mean(data$price, na.rm = TRUE)
```

The mean price of a ride in the whole dataset was 16.54$. We decided to later visualise the distribution of these prices, for the whole dataset and for Uber and Lyft separately. 

```{r}
mean_day_data <- data %>% group_by(date) %>% summarise(price = mean(price,na.rm=TRUE),.groups = "drop") %>% ungroup()
mean_day_data
```
```{r, warning=FALSE}
mean_hour_data <- data %>% group_by(hour) %>% summarise(price = mean(price,na.rm=TRUE),.groups = "drop") %>% ungroup()
mean_hour_data
```
Surprisingly, the mean price does not vary a lot depending on the hour of the day.

Now we can look at the distribution of the prices, over the whole data set.

```{r, warning=FALSE}
plot1 = ggplot(data, aes(x=price)) + geom_histogram(bins=15,color="darkblue", fill="lightblue") + xlab("Price ($)")  + ggtitle ("Distribution of prices, whole dataset") + theme(plot.title = element_text(hjust = 0.5))
plot1
```

The majority of the data is less than $\$50$, though there is a long tail : we can see that the global distribution is a slightly skewed towards lower prices, with more than 200,000 rides below the mean price. We can also see that this distribution has a long tail as there are some outliers in this dataset with a few rides that have prices between 50 and 100$.

Now we'll look at the distributions of Uber and Lyft seperately.

```{r, warning=FALSE}
plot1 = ggplot(filter(data, cab_type == "Uber"), aes(x=price)) + geom_histogram(bins=10,color="darkblue", fill="lightblue") + xlab("Price")  + ggtitle (" Uber") + theme(plot.title = element_text(hjust = 0.5))
plot2 = ggplot(filter(data, cab_type == "Lyft"), aes(x=price)) + geom_histogram(bins=10,color="red", fill="pink") + xlab("Price")  + ggtitle ("Lyft") + theme(plot.title = element_text(hjust = 0.5))


grid.arrange(plot1, plot2, ncol=2, top = textGrob("Distribution of prices for Uber and Lyft",gp=gpar(fontsize=18)))

```

We see similar distributions for Uber and Lyft. Additionally, they both look much like the distribution for the entire data set.

#### Number of rides

Now we'll explore the number of rides per hour.
```{r}
mean_hour_rides_data <- data %>% group_by(hour) %>% count() %>% ungroup()
mean_hour_rides_data
p <- ggplot(data = mean_hour_rides_data) +
    geom_line(aes(x = hour, y = n),colour = "red") + 
    geom_point(aes(x = hour, y = n),colour = "red") +
    xlab("Hour") +
    ylab(" Number of rides") +
    ggtitle("Number of rides per hour") +
    theme(plot.title = element_text(hjust = 0.5))

p
```

We see a lot of rides around midnight and a consistent number of rides throughout the midday (10am-4pm). The global trend seems to be that the number of rides decreases between midnight and 8 am and increases during the day, remaining very stable throughout the midday.

```{r}

data_uber = filter(data, cab_type == "Uber")
data_lyft = filter(data, cab_type == "Lyft")


plot1 = ggplot(data_uber %>% group_by(hour) %>% count() %>% ungroup()) +
    geom_line(aes(x = hour, y = n),colour = "blue") + 
    geom_point(aes(x = hour, y = n),colour = "blue") +
    xlab("Hour") +
    ylab(" Number of rides") + ggtitle (" Uber") + theme(plot.title = element_text(hjust = 0.5)) +
    ylim(c(10000,18000))

plot2 = ggplot(data_lyft %>% group_by(hour) %>% count() %>% ungroup(), aes(x=price)) + geom_line(aes(x = hour, y = n),colour = "pink") + 
    geom_point(aes(x = hour, y = n),colour = "pink") +
    xlab("Hour") +
    ylab(" Number of rides") + ggtitle (" Lyft") + theme(plot.title = element_text(hjust = 0.5)) +
    ylim(c(10000,18000))


grid.arrange(plot1, plot2, ncol=2, top = textGrob("Number of rides per hour",gp=gpar(fontsize=18)))

```

When we look at Uber and Lyft seperately, we see that Uber consistently has more rides at each hour than Lyft,  which makes sense since we have less data for Lyft.

```{r}


data_uber = filter(data, cab_type == "Uber")
data_lyft = filter(data, cab_type == "Lyft")


plot1 = ggplot(data_uber %>% group_by(date) %>% count() %>% ungroup()) +
    geom_line(aes(x = date, y = n),colour = "blue") + 
    geom_point(aes(x = date, y = n),colour = "blue") +
    xlab("Date") +
    ylab(" Number of rides") + ggtitle (" Uber") + theme(plot.title = element_text(hjust = 0.5)) +
    ylim(c(0,45000))

plot2 = ggplot(data_lyft %>% group_by(date) %>% count() %>% ungroup()) + geom_line(aes(x = date, y = n),colour = "pink") + 
    geom_point(aes(x = date, y = n),colour = "pink") +
    xlab("Date") +
    ylab(" Number of rides") + ggtitle (" Lyft") + theme(plot.title = element_text(hjust = 0.5)) +
    ylim(c(0,45000))


grid.arrange(plot1, plot2, ncol=2, top = textGrob("Number of rides per day",gp=gpar(fontsize=18)))

```

The same holds true for the number of rides per day. Our data spans the month of December and late November, and we can see some fluctuations in the number of rides per day that could be due to a range of phenomena such as special events, weekends...


#### Destinations and Source 

Let's look at all of our destination and sources and the number of rides corresponding to each of them.

```{r fig.dim = c(20,20), warnings=FALSE}
ggplot(data = data, aes(x = fct_infreq(destination),fill = cab_type))+ geom_bar(position = "dodge") + coord_flip() +
  xlab("Number of rides") +
  ylab(" Destination") + ggtitle ("Rides destination") + theme(plot.title = element_text(hjust = 0.5)) 
```

```{r fig.dim = c(20,20), warnings=FALSE}
ggplot(data = data, aes(x = fct_infreq(source),fill = cab_type))+ geom_bar(position = "dodge") + coord_flip() +
  xlab("Number of rides") +
  ylab("Source") + ggtitle ("Rides sources") + theme(plot.title = element_text(hjust = 0.5)) 
```

As above, Uber has more rides than Lyft to and from every location. However, the number of rides associated with each location are fairly consistent. Globally, the rides destination and source are uniformly distributed between all the values present in the dataset. The geospatial analysis will allow to go into further detail about the actually trips that are made.

Let's move on to looking at weather and number of rides.

```{r}
ggplot(data = data, aes(x = fct_infreq(short_summary),fill = cab_type))+ geom_bar(position = "dodge") +
  xlab("Short Summary") +
  ylab("Number of rides") + ggtitle ("Number of rides according to Short Summary") + theme(plot.title = element_text(hjust = 0.5)) +
  theme(legend.direction = "vertical",axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1))
```



```{r}
ggplot(data = data, aes(x = fct_infreq(icon),fill = cab_type))+ geom_bar(position = "dodge") +
  xlab("Icon") +
  ylab("Number of rides") + ggtitle ("Number of rides according to Icon") + theme(plot.title = element_text(hjust = 0.5)) + theme(legend.direction = "vertical",axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1))
```

Interestingly, the most rides correspond to the overcast and cloudy days and times. We would have expected rain to have a higher proportion of the data.

What if we look at the distribution of car types for each company : 
```{r}
ggplot(data = data, aes(x = fct_infreq(name),fill = cab_type))+ geom_bar(position = "dodge") +
  xlab("Type of ride") +
  ylab("Number of rides") + ggtitle ("Number of rides according to type of ride") + theme(plot.title = element_text(hjust = 0.5)) + theme(legend.direction = "vertical",axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1))
```

There are an equal number of car types for within each company. This probably has to do with how the dataset was created or sampled.

### Correlations between Price and other variables?

Let's take a quick look into some of the relationships between our variables.

#### Surge mulitplier 

```{r}
data_uber = filter(data, cab_type == "Uber")
data_lyft = filter(data, cab_type == "Lyft")


plot1 = ggplot(data_uber) + 
    geom_point(aes(x = surge_multiplier, y = price),colour = "blue") +
    xlab("Surge Multiplier") +
    ylab("Price") + ggtitle (" Uber") + theme(plot.title = element_text(hjust = 0.5)) 

plot2 = ggplot(data_lyft) +
    geom_point(aes(x = surge_multiplier, y = price),colour = "pink") +
    xlab("Surge Multiplier") +
    ylab("Price") + ggtitle (" Lyft") + theme(plot.title = element_text(hjust = 0.5)) 


grid.arrange(plot1, plot2, ncol=2, top = textGrob("Scatter plots of Surge Mutliplier VS Price",gp=gpar(fontsize=18)))

```

From our user experiences, we have the intuition that the surge multiplier will have an impact on the price of rides. We thus decided to visualise the correlation between price and surge multiplier. When looking at the left panel for Uber, we realised that the surge multiplier only takes value 1 for Uber, which is a problem we will tackle later on with our Machine Learning Models. 

For Lyft, the price does seem to be somewhat positively correlated to surge multiplier but it is not very clear.

```{r}
cor(data_lyft$price, data_lyft$surge_multiplier)
```

This supports our graphs. The correlation coefficient is quite low.

#### apparentTemperature
```{r, warning=FALSE}
data_uber = filter(data, cab_type == "Uber")
data_lyft = filter(data, cab_type == "Lyft")


plot1 = ggplot(data_uber) + 
    geom_point(aes(x = apparentTemperature, y = price),colour = "blue") +
    xlab("Apparent temperature") +
    ylab("Price") + ggtitle (" Uber") + theme(plot.title = element_text(hjust = 0.5)) +
    ylim(c(0,100))

plot2 = ggplot(data_lyft) +
    geom_point(aes(x = apparentTemperature, y = price),colour = "pink") +
    xlab(" Apparent temperature") +
    ylab("Price") + ggtitle ("Lyft") + theme(plot.title = element_text(hjust = 0.5)) +
    ylim(c(0,100))


grid.arrange(plot1, plot2, ncol=2, top = textGrob("Scatter plots of Apparent temperature VS Price",gp=gpar(fontsize=18)))

```

Looking at the apparent temperature variables is quite difficult given the amount of data. However, there doesn't seem to be much of a correlation.

#### Correlation Matrix between all usable variables (Uber)

```{r}
data_uber.numeric <- data_uber[,sapply(data_uber, is.numeric)]
```

Using the correlation matrix above, we created a more intuitive visualizations to examine the relationships. 

```{r}
cormat <- round(cor(data_uber.numeric, use = "complete.obs"),2)
head(cormat)
```


```{r fig.dim = c(22,22)}
library(reshape2)
melted_cormat <- melt(cormat)
ggplot(data = melted_cormat, aes(x=Var1, y=Var2, fill=value)) + 
  geom_tile() +
  scale_fill_gradient2(low = "blue", high = "red", mid = "white", 
   midpoint = 0, limit = c(-1,1), space = "Lab",
   name="Pearson\nCorrelation") + 
  theme(
  axis.title.x = element_blank(),
  axis.title.y = element_blank(),
  panel.border = element_blank(),
  panel.background = element_blank(),
  axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1),
  axis.ticks = element_blank(),
  legend.direction = "horizontal",
  legend.position="top") +  theme(aspect.ratio=1)
```

There's quite a bit of red and blue (meaning strong positive and negative correlations). However, many of the variables in our data set are associated with each other (ex: weather and temperature) so it isn't surprising to see a plot like this. We also see that price is correlated to distance.


Finally, let's look at the mean price of rides for each car type.

```{r}
mean_price_data <- data %>% group_by(name) %>% summarise(price = mean(price,na.rm=TRUE),.groups = "drop") %>% ungroup()
ggplot(data = mean_price_data, aes(x = name, y=price)) + geom_bar(stat='identity') +
  xlab("Type of ride") +
  ylab("Mean price") +
  ggtitle ("Mean price of ride according to type of ride") + theme(plot.title = element_text(hjust = 0.5)) + theme(legend.direction = "vertical",axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1))
```

This graph makes sense intuitively. The "nicer" rides are more expensive, and the more common rides are cheapest (Shared Lyft, Lyft, UberPool, and Uber).

As seen on the above histograms, there is large range of prices for rides in our data set. By stratifying by type of ride (ie. UberX and UberXL or Lyft and Lux), we can see that different ride times do not have the same mean price at all. This explains the distribution of prices that we observed.
